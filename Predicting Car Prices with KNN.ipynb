{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using KNN to Predict Car Prices\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/datasets/automobile) contains a variety of data that can be useful for evaluating prices of cars.  These data will provide a foundation for price prediction using K-nearest Neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setting up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c plotly chart-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset into a DataFrame\n",
    "cars = pd.read_csv('imports-85.data', header = None) # Data has no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no header, but we can get the header infomation from our source as below:\n",
    "\n",
    "* symboling: -3, -2, -1, 0, 1, 2, 3.\n",
    "* normalized-losses: continuous from 65 to 256.\n",
    "* make: alfa-romero, audi, bmw, chevrolet, dodge, honda, isuzu, jaguar, mazda, mercedes-benz, mercury, mitsubishi, nissan, peugot, plymouth, porsche, renault, saab, subaru, toyota, volkswagen, volvo\n",
    "* fuel-type: diesel, gas.\n",
    "* aspiration: std, turbo.\n",
    "* num-of-doors: four, two.\n",
    "* body-style: hardtop, wagon, sedan, hatchback, convertible.\n",
    "* drive-wheels: 4wd, fwd, rwd.\n",
    "* engine-location: front, rear.\n",
    "* wheel-base: continuous from 86.6 120.9.\n",
    "* length: continuous from 141.1 to 208.1.\n",
    "* width: continuous from 60.3 to 72.3.\n",
    "* height: continuous from 47.8 to 59.8.\n",
    "* curb-weight: continuous from 1488 to 4066.\n",
    "* engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    "* num-of-cylinders: eight, five, four, six, three, twelve, two.\n",
    "* engine-size: continuous from 61 to 326.\n",
    "* fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    "* bore: continuous from 2.54 to 3.94.\n",
    "* stroke: continuous from 2.07 to 4.17.\n",
    "* compression-ratio: continuous from 7 to 23.\n",
    "* horsepower: continuous from 48 to 288.\n",
    "* peak-rpm: continuous from 4150 to 6600.\n",
    "* city-mpg: continuous from 13 to 49.\n",
    "* highway-mpg: continuous from 16 to 54.\n",
    "* price: continuous from 5118 to 45400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string with all the header information\n",
    "header = '''1. symboling: -3, -2, -1, 0, 1, 2, 3.A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.\n",
    "\n",
    "2. normalized-losses: continuous from 65 to 256.\n",
    "3. make:\n",
    "alfa-romero, audi, bmw, chevrolet, dodge, honda,\n",
    "isuzu, jaguar, mazda, mercedes-benz, mercury,\n",
    "mitsubishi, nissan, peugot, plymouth, porsche,\n",
    "renault, saab, subaru, toyota, volkswagen, volvo\n",
    "4. fuel-type: diesel, gas.\n",
    "5. aspiration: std, turbo.\n",
    "6. num-of-doors: four, two.\n",
    "7. body-style: hardtop, wagon, sedan, hatchback, convertible.\n",
    "8. drive-wheels: 4wd, fwd, rwd.\n",
    "9. engine-location: front, rear.\n",
    "10. wheel-base: continuous from 86.6 120.9.\n",
    "11. length: continuous from 141.1 to 208.1.\n",
    "12. width: continuous from 60.3 to 72.3.\n",
    "13. height: continuous from 47.8 to 59.8.\n",
    "14. curb-weight: continuous from 1488 to 4066.\n",
    "15. engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    "16. num-of-cylinders: eight, five, four, six, three, twelve, two.\n",
    "17. engine-size: continuous from 61 to 326.\n",
    "18. fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    "19. bore: continuous from 2.54 to 3.94.\n",
    "20. stroke: continuous from 2.07 to 4.17.\n",
    "21. compression-ratio: continuous from 7 to 23.\n",
    "22. horsepower: continuous from 48 to 288.\n",
    "23. peak-rpm: continuous from 4150 to 6600.\n",
    "24. city-mpg: continuous from 13 to 49.\n",
    "25. highway-mpg: continuous from 16 to 54.\n",
    "26. price: continuous from 5118 to 45400.'''\n",
    "\n",
    "# After observing, split header by '. '\n",
    "header = header.split('. ')\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names from the list of headers\n",
    "import re\n",
    "pat = '[^:]*' # Matches anything that's not ':' therefore stops at first ':'\n",
    "columns = []\n",
    "for h in header:\n",
    "    m = re.search(pat, h)\n",
    "    if m: \n",
    "        found = m.group(0) # If pattern exist, extract group(0)\n",
    "        columns.append(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, len(columns) # Checking columns result and make sure all of the headers are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to cars DataFrame and exclude the first element in columns that shouldn't be included\n",
    "cars.columns = columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 26\n",
    "cars.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the dataset, we can determine the columns that are numerical and can be used as features as below:\n",
    "\n",
    "`'symboling', 'normalized-losses', 'num-of-doors', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'num-of-cylinders', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg'`\n",
    "\n",
    "Columns 'num-of-doors', 'num-of-cylinders' are not numerical but can be converted to numerical.\n",
    "\n",
    "Column 'price' will be our target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only selected features and target columns\n",
    "cars_selected = cars[['symboling', 'normalized-losses', 'num-of-doors', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'num-of-cylinders', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From data exploration, missing values are replaced with '?' in column 'normalized-losses'; the following will replace '?' with null(NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cars_selected = cars_selected.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings in columns 'num-of-doors', 'num-of-cylinders' to numerical values\n",
    "cars_selected['num-of-doors'] = cars_selected['num-of-doors'].map({'two':2, 'four':4})\n",
    "cars_selected['num-of-cylinders'] = cars_selected['num-of-cylinders'].map({'eight': 8,\n",
    "                             'five':5, \n",
    "                             'four':4,\n",
    "                             'six':6, \n",
    "                             'three':3, \n",
    "                             'twelve':12, \n",
    "                             'two':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns in the dataframe to type float \n",
    "cars_selected = cars_selected.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataframe\n",
    "cars_selected.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 4 missing car prices, dropping these rows will not compromise the prediction. \n",
    "\n",
    "There are also 2 missing values in the `num-of-doors` column. The original dataframe should tell us the car make and body-type so we can likely figure out the number of doors there.\n",
    "\n",
    "For the other columns, it is reasonable to fill the missing values with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing price\n",
    "cars_selected.dropna(subset = ['price'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the rows with missing num-of-doors value\n",
    "idx = cars_selected[cars_selected['num-of-doors'].isnull()].index\n",
    "cars.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dodge and Mazda sedans are the culprits - a light application of Google-fu and we can find that they are both 4-door models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign door number values to rows with the missing values \n",
    "cars_selected.loc[idx, 'num-of-doors'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing values in the rest of columns with missing values with their column mean \n",
    "cars_selected = cars_selected.fillna(cars_selected.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no null values remain\n",
    "cars_selected.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature columns come next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "cars_features = cars_selected.drop('price', axis = 1)\n",
    "cars_features = (cars_features - cars_features.mean())/np.std(cars_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_clean = pd.concat([cars_features, cars_selected.price], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building the Univariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model & validation methods from sklearn \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training & validation function\n",
    "def knn_train_test(feature_col, target_col, df):\n",
    "    train, test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(train[feature_col], train[target_col])\n",
    "    predictions = model.predict(test[feature_col])\n",
    "    mse = mean_squared_error(test[target_col], predictions)\n",
    "    rmse = np.sqrt(np.abs(mse))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using columns with numerical data to train and test the univariate models comes next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = {}\n",
    "feature_cols = cars_features.columns\n",
    "\n",
    "for col in feature_cols:\n",
    "    rmses[col] = knn_train_test([col], 'price', cars_clean)\n",
    "\n",
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the key of the minimum value in the rmses dictionary \n",
    "min(rmses, key=rmses.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows that `horsepower` performed the best using the k=5 default.\n",
    "\n",
    "Modifying the `knn_train_test()` function from above to accept a parameter for k will also make the design more fail-safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify knn_train_test() function \n",
    "def knn_train_test(feature_col, target_col, df, k):\n",
    "    train, test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "    model = KNeighborsRegressor(n_neighbors = k)\n",
    "    model.fit(train[feature_col], train[target_col])\n",
    "    predictions = model.predict(test[feature_col])\n",
    "    mse = mean_squared_error(test[target_col], predictions)\n",
    "    rmse = np.sqrt(np.abs(mse))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each selected column, additional k values can be used to create, train, and test a univariate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of k_values\n",
    "k_values = range(1,10,2)\n",
    "\n",
    "# Create a dataframe to store the result\n",
    "univariate_k_rmse = pd.DataFrame(data = 0, index = range(len(k_values)),columns = feature_cols)\n",
    "univariate_k_rmse['k_values'] = k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_cols:\n",
    "    for n in k_values:\n",
    "        univariate_k_rmse.loc[univariate_k_rmse.k_values == n, col] = knn_train_test([col], 'price', cars_clean, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_k_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while a table is always nice, a picture can speak a thousand words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize with plotly bar graph and slider\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# Initialize a set of colors\n",
    "colors = ['#30336b',\n",
    "          '#4834d4', '#686de0',\n",
    "          '#22a6b3', '#7ed6df']\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "i = 0\n",
    "# Add traces, one for each slider step\n",
    "for step in np.arange(1, 10, 2):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            visible=False,\n",
    "            name=\"k-value = \" + str(step),\n",
    "            x=feature_cols,\n",
    "            y=univariate_k_rmse.loc[i, feature_cols],\n",
    "            marker=dict(\n",
    "                color=colors[i]\n",
    "            )))\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "# Make first trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "\n",
    "for i in range(len(fig.data)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": \"Slider switched to K-Value: \" + str(k_values[i])}],\n",
    "        label = str(k_values[i]) # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"K-Value: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "fig.layout.update(\n",
    "    sliders=sliders,\n",
    "    yaxis=dict(range=[0,1.2e4])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building the Multivariate Model\n",
    "\n",
    "In order to accommodate more than one column, the next step is to update the model.\n",
    "\n",
    "This will involve training the `knn_train_test()` function with additional features from the previous step and a default k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean rmse for each feature from previous step\n",
    "best_five = univariant_k_rmse[feature_cols].mean().sort_values().index[:5]\n",
    "best_eight = univariant_k_rmse[feature_cols].mean().sort_values().index[:8]\n",
    "best_eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best 2,3,4,5 features from the previous step to train and test a multivariate k-nearest neighbors model\n",
    "for i in range(7):\n",
    "    rmse = knn_train_test(feature_col = best_eight[:i+1], target_col = 'price', df = cars_clean, k = 5)\n",
    "    i += 1\n",
    "    print('RMSE from default k and feature columns', list(best_eight[:i+1]), 'is: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three models that performed the best can be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list of k values from 1 to 25\n",
    "multi_k = range(1,26)\n",
    "\n",
    "# Initialize a dataframe to store result \n",
    "models = ['3_best_features', '4_best_features', '5_best_features']\n",
    "multivariate_k_rmse = pd.DataFrame(data = 0, columns = models, index = range(len(multi_k)))\n",
    "multivariate_k_rmse['k_values'] = multi_k\n",
    "\n",
    "# Fit the best 3 models from the previous step \n",
    "for i in range(3):\n",
    "    for n in multi_k:\n",
    "        rmse = knn_train_test(best_five[:i+2], 'price', cars_clean, n)\n",
    "        multivariate_k_rmse.loc[multivariate_k_rmse.k_values == n, models[i]] = rmse \n",
    "    \n",
    "multivariate_k_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to visualize the results, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with plotly line graph and slider\n",
    "\n",
    "# Initialize a set of colors\n",
    "colors = ['#d54062', '#ffa36c','#799351']\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "i = 0\n",
    "# Add traces, one for each slider step\n",
    "for step in models:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            visible=False,\n",
    "            name=\"Number of features = \" + str(step),\n",
    "            x=multivariate_k_rmse.k_values,\n",
    "            y=multivariate_k_rmse[step],\n",
    "            marker=dict(\n",
    "                color=colors[i]\n",
    "            )))\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "# Make first trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "\n",
    "for i in range(len(fig.data)):\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(fig.data)},\n",
    "              {\"title\": \"Slider switched to: \" + str(models[i])}],\n",
    "        label = str(models[i]) # layout attribute\n",
    "    )\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [dict(\n",
    "    active = 0,\n",
    "    currentvalue={\"prefix\": \"Model: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=steps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    yaxis=dict(range=[1500, 3600]),\n",
    "    xaxis = dict(range = [1,25],\n",
    "                nticks = 25)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "In the project, KNN was used to experiment with car prices, tuning the model with an array of features and k_values.  Interactable visualisation was also used to allow the reader to see the variation in the experiment results.  \n",
    "\n",
    "Some of the findings:\n",
    "* In this project, with a default k = 5, as the number of top features oscillates, from increasing, where the RMSE value drops, but then increases again. This indicates that as features increase the better trained model loses validity; it appears that feature relevance does play a role.\n",
    "* And much like rings, there is no 'one K to rule them all.' Instead, each feature responds differently to different k-values. Also, different combinations of features respond differently to different k-values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
